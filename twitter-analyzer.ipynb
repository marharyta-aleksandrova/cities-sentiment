{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "from sentiment_analysis_spanish import sentiment_analysis\n",
    "from requests.sessions import dispatch_hook\n",
    "from collections import Counter\n",
    "\n",
    "import time\n",
    "\n",
    "import json\n",
    "\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "\n",
    "import yaml\n",
    "import requests\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for analysis of text in Spanish\n",
    "sentiment_spanish = sentiment_analysis.SentimentAnalysisSpanish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dowloading data from Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert your connection information below\n",
    "# https://developer.twitter.com/en/docs/twitter-api/getting-started/getting-access-to-the-twitter-api\n",
    "\n",
    "consumer_key = 'XXX'\n",
    "consumer_secret = 'YYY'\n",
    "access_token = 'ZZZ'\n",
    "access_token_secret = 'WWW'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Quart de Poblet'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data for the last 7 days (available with free Twitter API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1000\n",
    "tweets = tweepy.Cursor(\n",
    "    api.search_tweets,\n",
    "    q=query,\n",
    "    tweet_mode=\"extended\",\n",
    ").items(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the data for the last 30 days (available with academic Twitter API). `label` should contain the name of your application created at twitter developer portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1000\n",
    "tweets = tweepy.Cursor(\n",
    "    api.search_30_day, \n",
    "    label='dev30days', \n",
    ").items(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list = [tweet._json for tweet in tweets]\n",
    "print('Dowloaded {} tweets'.format(len(tweets_list)))\n",
    "tweet_df = pd.DataFrame(tweets_list)\n",
    "tweet_df['created_at'] = tweet_df['created_at'].astype('datetime64[ns]')\n",
    "file_name = '{}.txt'.format(query)\n",
    "with open(file_name, 'w') as out_f:\n",
    "    json.dump(tweets_list, out_f)\n",
    "print('The tweets were saved into {}'.format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading tweets stored in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file contains tweets collected for the query \"Quart de Poblet\"\n",
    "file_name = 'Quart de Poblet.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name) as in_file:\n",
    "    tweets_json = json.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.DataFrame(tweets_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get full text of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'text' in tweets_df.columns:\n",
    "    text_arr = tweets_df['text'].values\n",
    "    ext_tweet_arr = tweets_df['extended_tweet'].values\n",
    "    num_changed = 0\n",
    "    for i in range(0, len(ext_tweet_arr)):\n",
    "        if type(ext_tweet_arr[i]) == dict:\n",
    "            num_changed += 1\n",
    "            #print(ext_tweet_arr[i]['full_text'])\n",
    "            text_arr[i] = ext_tweet_arr[i]['full_text']\n",
    "        pass\n",
    "    print('changed {} of {}'.format(num_changed, len(text_arr)))\n",
    "    tweets_df['full_text'] = text_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding sentiment analysis results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_results = [sentiment_spanish.sentiment(text) for text in tweets_df['full_text'].values]\n",
    "len(sentiment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['Sentiment'] = sentiment_results\n",
    "tweets_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can set thresholds for labeling tweets as positive, negative and neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_class_arr = []\n",
    "for res in tweets_df['Sentiment'].values:\n",
    "    if res > 0.99:\n",
    "        sent = 'POS'\n",
    "    elif res > 0.001:\n",
    "        sent = 'NEU'\n",
    "    else:\n",
    "        sent = 'NEG'\n",
    "        pass\n",
    "    sent_class_arr.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['Sentiment_class'] = sent_class_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.groupby('Sentiment_class')['created_at'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get user location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_loc_arr = [user['location'] for user in tweets_df['user'].values]\n",
    "len(user_loc_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['user_loc'] = user_loc_arr\n",
    "tweets_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing user location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_locs = tweets_df['user_loc'].unique()\n",
    "print(len(unique_locs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Users with location')\n",
    "print(sum(x is not None for x in user_loc_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_loc_arr[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the user-location is not standardised. It can be done, however, with other tools, such as google maps. Below, we will download a file with these locations being already mapped Google Maps queries. From these queries, we can extract geographical coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding geo information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc_name = pd.read_csv('location_name.txt', sep='\\t', header=None)\n",
    "df_loc_name.columns = ['name']\n",
    "df_loc_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc_url = pd.read_csv('location_url.txt', sep='\\t', header=None)\n",
    "df_loc_name['url'] = df_loc_url[0]\n",
    "df_loc_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parcing url of locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_arr = []\n",
    "lat_arr = []\n",
    "lon_arr = []\n",
    "\n",
    "for url in df_loc_name['url'].values:\n",
    "    tmp = url.split('/')\n",
    "    name_arr.append(tmp[5])\n",
    "    loc = tmp[6][1:-3].split(',')\n",
    "    #print(loc)\n",
    "    lat_arr.append(float(loc[0]))\n",
    "    lon_arr.append(float(loc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loc_name['disp_name'] = name_arr\n",
    "df_loc_name['lat'] = lat_arr\n",
    "df_loc_name['lon'] = lon_arr\n",
    "df_loc_name.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additing location information to tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disp_name = []\n",
    "lat_arr = []\n",
    "lon_arr = []\n",
    "for user_loc in tweets_df['user_loc'].values:\n",
    "    df_row = df_loc_name[df_loc_name['name'] == user_loc]\n",
    "    if len(df_row) > 0:\n",
    "        disp_name.append(df_row['disp_name'].values[0])\n",
    "        lat_arr.append(df_row['lat'].values[0])\n",
    "        lon_arr.append(df_row['lon'].values[0])\n",
    "        pass\n",
    "    else:\n",
    "        disp_name.append(None)\n",
    "        lat_arr.append(None)\n",
    "        lon_arr.append(None)\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "tweets_df['user_loc_disp_name'] = disp_name\n",
    "tweets_df['user_loc_lat'] = lat_arr\n",
    "tweets_df['user_loc_lon'] = lon_arr\n",
    "\n",
    "tweets_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding day and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_arr = []\n",
    "day_hour_arr = []\n",
    "time_arr = []\n",
    "hour_arr = []\n",
    "for val in tweets_df['created_at'].values:\n",
    "    datetime_object = datetime.strptime(val, '%a %b %d %H:%M:%S +0000 %Y')\n",
    "    day_arr.append(datetime_object.date())\n",
    "    time_arr.append(datetime_object.time())\n",
    "    hour_arr.append(datetime_object.time().hour)\n",
    "    day_hour_arr.append(datetime_object.replace(minute=0).replace(second=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df['day'] = day_arr\n",
    "tweets_df['time'] = time_arr\n",
    "tweets_df['hour'] = hour_arr\n",
    "tweets_df['day_hour'] = day_hour_arr\n",
    "\n",
    "tweets_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = len(tweets_df)\n",
    "print('Number of tweets: {}'.format(tot))\n",
    "print('Starting date   : {}'.format(tweets_df['day'].min()))\n",
    "print('End date        : {}'.format(tweets_df['day'].max()))\n",
    "sent_class = tweets_df.groupby(['Sentiment_class'])['day'].count()\n",
    "print('Negative        : {} ({}%)'.format(sent_class['NEG'], \n",
    "                                          np.round(sent_class['NEG'] / tot * 100, 2)))\n",
    "print('Neutral         : {} ({}%)'.format(sent_class['NEU'], \n",
    "                                          np.round(sent_class['NEU'] / tot * 100, 2)))\n",
    "print('Positive        : {} ({}%)'.format(sent_class['POS'], \n",
    "                                          np.round(sent_class['POS'] / tot * 100, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.strptime('2021-12-20', '%Y-%m-%d').date()\n",
    "end_date = datetime.strptime('2022-01-19', '%Y-%m-%d').date()\n",
    "#print(start_date)\n",
    "#print(end_date)\n",
    "tweets_df_tmp = tweets_df[(tweets_df['day'] >= start_date) & (tweets_df['day'] <= end_date)]\n",
    "print('Chosen tweets: {} ({}%)'.format(\n",
    "    len(tweets_df_tmp), np.round(len(tweets_df_tmp)/len(tweets_df)*100, 2)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tweets_df_tmp.groupby('day')['created_at'].count().reset_index()\n",
    "tmp.columns = ['day', '# of tweets']\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of tweets per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "px.line(data_frame=tmp, x='day', y=['# of tweets'], title='Number of tweets per day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.pivot_table(tweets_df_tmp, index=[\"day\"], columns=[\"Sentiment_class\"], \n",
    "                     values=[\"created_at\"], aggfunc='count')\n",
    "tmp.reset_index(inplace=True)\n",
    "tmp.columns = ['day', 'NEG', 'NEU', 'POS']\n",
    "# replace nans with zeros\n",
    "tmp['NEG'] = tmp['NEG'].fillna(0)\n",
    "tmp['NEU'] = tmp['NEU'].fillna(0)\n",
    "tmp['POS'] = tmp['POS'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data_frame=tmp, x='day', title='Number of tweets per day', y=[  \n",
    "    'NEU',\n",
    "    'NEG',\n",
    "    #'POS',\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.bar(data_frame=tmp, x='day', title='Number of tweets per day', y=[  \n",
    "    'NEU',\n",
    "    'NEG',\n",
    "    'POS',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of tweets per hour (during the day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tweets_df_tmp.groupby('hour')['created_at'].count().reset_index()\n",
    "tmp.columns = ['hour', '# tweets']\n",
    "px.line(data_frame=tmp, x='hour', title='Total number of tweets per hour', y=['# tweets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add 0 where required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = tweets_df_tmp.groupby('day_hour')['created_at'].count().reset_index()\n",
    "tmp.columns = ['day_hour', '# tweets']\n",
    "#px.line(data_frame=tmp, x='day_hour', title='Total number of tweets per hour', y=['# tweets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_num_arr = []\n",
    "full_date_arr = []\n",
    "available_date_arr = tmp['day_hour'].tolist()\n",
    "available_count_arr = tmp['# tweets']\n",
    "\n",
    "full_date_arr.append(available_date_arr[0])\n",
    "full_num_arr.append(available_count_arr[0])\n",
    "for i in range(1, len(available_date_arr)):\n",
    "    next_date = available_date_arr[i]\n",
    "    next_count = available_count_arr[i]\n",
    "    last_date = full_date_arr[-1]\n",
    "    while next_date > last_date + timedelta(hours=1):\n",
    "        full_date_arr.append(last_date + timedelta(hours=1))\n",
    "        full_num_arr.append(0)\n",
    "        last_date = full_date_arr[-1]\n",
    "        pass\n",
    "    full_date_arr.append(next_date)\n",
    "    full_num_arr.append(next_count)\n",
    "    pass\n",
    "tmp_new = pd.DataFrame()\n",
    "tmp_new['date'] = full_date_arr\n",
    "tmp_new['# tweets'] = full_num_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tmp_new.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(data_frame=tmp_new, x='date', title='Total number of tweets per hour', y=['# tweets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geographical visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_to_geo_df = tweets_df_tmp.groupby(by=['user_loc_disp_name', 'user_loc_lat', 'user_loc_lon'])[['created_at']].count().reset_index()\n",
    "tweets_to_geo_df.columns = ['user_loc_disp_name', 'user_loc_lat', 'user_loc_lon', '# tweets']\n",
    "\n",
    "num_with_geo = tweets_to_geo_df['# tweets'].sum()\n",
    "print('Number of tweets with geo information {} ({}%)'.format(\n",
    "    num_with_geo, np.round( num_with_geo/len(tweets_df_tmp)*100, 2)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Top geo locations:')\n",
    "tweets_to_geo_df.sort_values(by='# tweets', ascending=False)[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(tweets_to_geo_df, lat=\"user_loc_lat\", lon='user_loc_lon',\n",
    "                     color=\"# tweets\",\n",
    "                     hover_name=\"user_loc_disp_name\", \n",
    "                     #size=\"created_at\", \n",
    "                     projection=\"natural earth\"\n",
    "                    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Per sentiment class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_classes = [\n",
    "    'NEG', \n",
    "    #'NEU',\n",
    "    #'POS',\n",
    "]\n",
    "\n",
    "tweets_to_geo_df = tweets_df_tmp[tweets_df_tmp['Sentiment_class'].isin(sentiment_classes)].groupby(by=['user_loc_disp_name', 'user_loc_lat', 'user_loc_lon'])[['created_at']].count().reset_index()\n",
    "tweets_to_geo_df.columns = ['user_loc_disp_name', 'user_loc_lat', 'user_loc_lon', '# tweets']\n",
    "\n",
    "num_with_geo = tweets_to_geo_df['# tweets'].sum()\n",
    "print('Number of tweets with geo information {}'.format(num_with_geo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Top geo locations:')\n",
    "tweets_to_geo_df.sort_values(by='# tweets', ascending=False)[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.scatter_geo(tweets_to_geo_df, lat=\"user_loc_lat\", lon='user_loc_lon',\n",
    "                     color=\"# tweets\",\n",
    "                     hover_name=\"user_loc_disp_name\", \n",
    "                     #size=\"created_at\", \n",
    "                     projection=\"natural earth\",\n",
    "                     title='Number of tweets with sentiment in {}'.format(sentiment_classes)\n",
    "                    )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images associated with tweets are stored in the `extended_entities` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ids of tweets that contain media:')\n",
    "possible_ids = tweets_df[~tweets_df['extended_entities'].isna()]['extended_entities'].index.tolist()\n",
    "possible_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us analyse the image associated with the tweet with id=94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_id = possible_ids[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = tweets_df[~tweets_df['extended_entities'].isna()]['extended_entities'][tweet_id]['media'][0]['media_url']\n",
    "\n",
    "image_source = requests.get(image_url)\n",
    "image_file = \"sample_image.jpg\" \n",
    "file = open(image_file, \"wb\")\n",
    "file.write(image_source.content)\n",
    "file.close()\n",
    "\n",
    "img = image.load_img(image_file, target_size=(224, 224))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "\n",
    "preds = model.predict(x)\n",
    "# decode the results into a list of tuples (class, description, probability)\n",
    "# (one such list for each sample in the batch)\n",
    "print('Predicted:')\n",
    "for el in decode_predictions(preds, top=3)[0]:\n",
    "    print('\\t {} - {}'.format(el[1], el[2]))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
